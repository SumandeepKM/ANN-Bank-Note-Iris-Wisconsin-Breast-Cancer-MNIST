{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affiliated-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-kelly",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "focal-programmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"IRIS.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "classical-member",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-versicolor    50\n",
       "Iris-setosa        50\n",
       "Iris-virginica     50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"species\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incorrect-standard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressed-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quantitative-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "enormous-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-estate",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "decimal-consistency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-farming",
   "metadata": {},
   "source": [
    "# Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vulnerable-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-reconstruction",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "supported-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "electric-nothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-circle",
   "metadata": {},
   "source": [
    "# Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "advisory-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-metadata",
   "metadata": {},
   "source": [
    "# Training the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "premier-charlotte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "4/4 [==============================] - 1s 2ms/step - loss: 1.2059 - accuracy: 0.2806\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1827 - accuracy: 0.2919\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1454 - accuracy: 0.3219\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1309 - accuracy: 0.3073\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1023 - accuracy: 0.3106\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1246 - accuracy: 0.2744\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0788 - accuracy: 0.3394\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0859 - accuracy: 0.3042\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0710 - accuracy: 0.3212\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0625 - accuracy: 0.3471\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0263 - accuracy: 0.3827\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0021 - accuracy: 0.4140\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0008 - accuracy: 0.4144\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9850 - accuracy: 0.4463\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9786 - accuracy: 0.4254\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9837 - accuracy: 0.4198\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9484 - accuracy: 0.4921\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9376 - accuracy: 0.5100\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9241 - accuracy: 0.5248\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9345 - accuracy: 0.5367\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9386 - accuracy: 0.5142\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9257 - accuracy: 0.5450\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9553 - accuracy: 0.5202\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9308 - accuracy: 0.5390\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9113 - accuracy: 0.5587\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9363 - accuracy: 0.5300\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8902 - accuracy: 0.6348\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9028 - accuracy: 0.6235\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9110 - accuracy: 0.5767\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8689 - accuracy: 0.6079\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9048 - accuracy: 0.6008\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9035 - accuracy: 0.5790\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8646 - accuracy: 0.5810\n",
      "Epoch 34/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8699 - accuracy: 0.5946\n",
      "Epoch 35/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8861 - accuracy: 0.5844\n",
      "Epoch 36/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8289 - accuracy: 0.6921\n",
      "Epoch 37/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8758 - accuracy: 0.6569\n",
      "Epoch 38/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8361 - accuracy: 0.6363\n",
      "Epoch 39/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8597 - accuracy: 0.6519\n",
      "Epoch 40/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8458 - accuracy: 0.6573\n",
      "Epoch 41/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8527 - accuracy: 0.6635\n",
      "Epoch 42/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8231 - accuracy: 0.6615\n",
      "Epoch 43/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8395 - accuracy: 0.6594\n",
      "Epoch 44/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8449 - accuracy: 0.6877\n",
      "Epoch 45/250\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7873 - accuracy: 0.6971\n",
      "Epoch 46/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7948 - accuracy: 0.6596\n",
      "Epoch 47/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8279 - accuracy: 0.6377\n",
      "Epoch 48/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7890 - accuracy: 0.6898\n",
      "Epoch 49/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7848 - accuracy: 0.6700\n",
      "Epoch 50/250\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8112 - accuracy: 0.6804\n",
      "Epoch 51/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7558 - accuracy: 0.7148\n",
      "Epoch 52/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8086 - accuracy: 0.6440\n",
      "Epoch 53/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8223 - accuracy: 0.6837\n",
      "Epoch 54/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7677 - accuracy: 0.6798\n",
      "Epoch 55/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7823 - accuracy: 0.7163\n",
      "Epoch 56/250\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7675 - accuracy: 0.6994\n",
      "Epoch 57/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7921 - accuracy: 0.6994\n",
      "Epoch 58/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7736 - accuracy: 0.6900\n",
      "Epoch 59/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7914 - accuracy: 0.6715\n",
      "Epoch 60/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7965 - accuracy: 0.6288\n",
      "Epoch 61/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7624 - accuracy: 0.6831\n",
      "Epoch 62/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7680 - accuracy: 0.7260\n",
      "Epoch 63/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7331 - accuracy: 0.7125\n",
      "Epoch 64/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7712 - accuracy: 0.7104\n",
      "Epoch 65/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7343 - accuracy: 0.7398\n",
      "Epoch 66/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7242 - accuracy: 0.7400\n",
      "Epoch 67/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7394 - accuracy: 0.7369\n",
      "Epoch 68/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7307 - accuracy: 0.7569\n",
      "Epoch 69/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7050 - accuracy: 0.7142\n",
      "Epoch 70/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7666 - accuracy: 0.6913\n",
      "Epoch 71/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7211 - accuracy: 0.7310\n",
      "Epoch 72/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7554 - accuracy: 0.7008\n",
      "Epoch 73/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7104 - accuracy: 0.7625\n",
      "Epoch 74/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7157 - accuracy: 0.7365\n",
      "Epoch 75/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.7625\n",
      "Epoch 76/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.7573\n",
      "Epoch 77/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.7615\n",
      "Epoch 78/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.7458\n",
      "Epoch 79/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.7292\n",
      "Epoch 80/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.7356\n",
      "Epoch 81/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.7890\n",
      "Epoch 82/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.7735\n",
      "Epoch 83/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.8037\n",
      "Epoch 84/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.7725\n",
      "Epoch 85/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.7892\n",
      "Epoch 86/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7010 - accuracy: 0.7277\n",
      "Epoch 87/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.8017\n",
      "Epoch 88/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.7454\n",
      "Epoch 89/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.7727\n",
      "Epoch 90/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.7883\n",
      "Epoch 91/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.7531\n",
      "Epoch 92/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6320 - accuracy: 0.7962\n",
      "Epoch 93/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.8142\n",
      "Epoch 94/250\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6201 - accuracy: 0.8090\n",
      "Epoch 95/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.7985\n",
      "Epoch 96/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.8277\n",
      "Epoch 97/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.8058\n",
      "Epoch 98/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.8142\n",
      "Epoch 99/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.8058\n",
      "Epoch 100/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.8321\n",
      "Epoch 101/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.8362\n",
      "Epoch 102/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.8394\n",
      "Epoch 103/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.8206\n",
      "Epoch 104/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.8021\n",
      "Epoch 105/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.8158\n",
      "Epoch 106/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.8721\n",
      "Epoch 107/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.8431\n",
      "Epoch 108/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.8535\n",
      "Epoch 109/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.8483\n",
      "Epoch 110/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.8515\n",
      "Epoch 111/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.8265\n",
      "Epoch 112/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8671\n",
      "Epoch 113/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.8629\n",
      "Epoch 114/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.8485\n",
      "Epoch 115/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8777\n",
      "Epoch 116/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8694\n",
      "Epoch 117/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8717\n",
      "Epoch 118/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.8417\n",
      "Epoch 119/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.8940\n",
      "Epoch 120/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8950\n",
      "Epoch 121/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.9044\n",
      "Epoch 122/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.8735\n",
      "Epoch 123/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.9110\n",
      "Epoch 124/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8746\n",
      "Epoch 125/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.9162\n",
      "Epoch 126/250\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.8975\n",
      "Epoch 127/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8787\n",
      "Epoch 128/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.9215\n",
      "Epoch 129/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8873\n",
      "Epoch 130/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.9029\n",
      "Epoch 131/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.9019\n",
      "Epoch 132/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8988\n",
      "Epoch 133/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.9167\n",
      "Epoch 134/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.9271\n",
      "Epoch 135/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.9323\n",
      "Epoch 136/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.9156\n",
      "Epoch 137/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.9250\n",
      "Epoch 138/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.9323\n",
      "Epoch 139/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.9354\n",
      "Epoch 140/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.9083\n",
      "Epoch 141/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.9229\n",
      "Epoch 142/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.9229\n",
      "Epoch 143/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8958\n",
      "Epoch 144/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.9167\n",
      "Epoch 145/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.9094\n",
      "Epoch 146/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.9177\n",
      "Epoch 147/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.9104\n",
      "Epoch 148/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.9229\n",
      "Epoch 149/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.9096\n",
      "Epoch 150/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.9335\n",
      "Epoch 151/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.9252\n",
      "Epoch 152/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.9408\n",
      "Epoch 153/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.9325\n",
      "Epoch 154/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.9190\n",
      "Epoch 155/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.9200\n",
      "Epoch 156/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.9304\n",
      "Epoch 157/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.9221\n",
      "Epoch 158/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.9283\n",
      "Epoch 159/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2881 - accuracy: 0.9429\n",
      "Epoch 160/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.9263\n",
      "Epoch 161/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.9315\n",
      "Epoch 162/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.9367\n",
      "Epoch 163/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.9044\n",
      "Epoch 164/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.9304\n",
      "Epoch 165/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.9190\n",
      "Epoch 166/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.9304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.9221\n",
      "Epoch 168/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.9210\n",
      "Epoch 169/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.9075\n",
      "Epoch 170/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2637 - accuracy: 0.9513\n",
      "Epoch 171/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.9315\n",
      "Epoch 172/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.9356\n",
      "Epoch 173/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.9283\n",
      "Epoch 174/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.9283\n",
      "Epoch 175/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.9377\n",
      "Epoch 176/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2869 - accuracy: 0.9158\n",
      "Epoch 177/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8927\n",
      "Epoch 178/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.9167\n",
      "Epoch 179/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8948\n",
      "Epoch 180/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.9115\n",
      "Epoch 181/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.9021\n",
      "Epoch 182/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9281\n",
      "Epoch 183/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.9167\n",
      "Epoch 184/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.9010\n",
      "Epoch 185/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9281\n",
      "Epoch 186/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.9146\n",
      "Epoch 187/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9304\n",
      "Epoch 188/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2181 - accuracy: 0.9440\n",
      "Epoch 189/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.9065\n",
      "Epoch 190/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9158\n",
      "Epoch 191/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.9013\n",
      "Epoch 192/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9356\n",
      "Epoch 193/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2677 - accuracy: 0.9075\n",
      "Epoch 194/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9158\n",
      "Epoch 195/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9304\n",
      "Epoch 196/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9190\n",
      "Epoch 197/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9367\n",
      "Epoch 198/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9242\n",
      "Epoch 199/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2418 - accuracy: 0.9210\n",
      "Epoch 200/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.9179\n",
      "Epoch 201/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9481\n",
      "Epoch 202/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9452\n",
      "Epoch 203/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2609 - accuracy: 0.9129\n",
      "Epoch 204/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9337\n",
      "Epoch 205/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.9254\n",
      "Epoch 206/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9473\n",
      "Epoch 207/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9577\n",
      "Epoch 208/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9390\n",
      "Epoch 209/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2054 - accuracy: 0.9473\n",
      "Epoch 210/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9379\n",
      "Epoch 211/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9538\n",
      "Epoch 212/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9381\n",
      "Epoch 213/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9392\n",
      "Epoch 214/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 0.9277\n",
      "Epoch 215/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9308\n",
      "Epoch 216/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9558\n",
      "Epoch 217/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9350\n",
      "Epoch 218/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9538\n",
      "Epoch 219/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9444\n",
      "Epoch 220/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9621\n",
      "Epoch 221/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1976 - accuracy: 0.9371\n",
      "Epoch 222/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9642\n",
      "Epoch 223/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9465\n",
      "Epoch 224/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9540\n",
      "Epoch 225/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9571\n",
      "Epoch 226/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9560\n",
      "Epoch 227/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1928 - accuracy: 0.9456\n",
      "Epoch 228/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9560\n",
      "Epoch 229/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9529\n",
      "Epoch 230/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.9540\n",
      "Epoch 231/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9456\n",
      "Epoch 232/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9529\n",
      "Epoch 233/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9519\n",
      "Epoch 234/250\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2081 - accuracy: 0.9425\n",
      "Epoch 235/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9435\n",
      "Epoch 236/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9529\n",
      "Epoch 237/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.9592\n",
      "Epoch 238/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9623\n",
      "Epoch 239/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 0.9633\n",
      "Epoch 240/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9633\n",
      "Epoch 241/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9415\n",
      "Epoch 242/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9581\n",
      "Epoch 243/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9508\n",
      "Epoch 244/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9612\n",
      "Epoch 245/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9415\n",
      "Epoch 246/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9394\n",
      "Epoch 247/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.9446\n",
      "Epoch 248/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9540\n",
      "Epoch 249/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9592\n",
      "Epoch 250/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1801 - accuracy: 0.9269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1650658460>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model = ann.fit(X_train, y_train, batch_size = 32, epochs = 250)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "renewable-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 51\n",
      "Trainable params: 51\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-review",
   "metadata": {},
   "source": [
    "# Predicting the Train set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "protected-waters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.40075712e-03, 1.80480868e-01, 8.18118393e-01],\n",
       "       [1.00933388e-01, 6.16456032e-01, 2.82610536e-01],\n",
       "       [9.89219487e-01, 8.23104382e-03, 2.54951813e-03],\n",
       "       [4.28972626e-03, 2.66916364e-01, 7.28793919e-01],\n",
       "       [8.67644412e-05, 2.52589937e-02, 9.74654198e-01],\n",
       "       [1.36343360e-01, 7.19963193e-01, 1.43693432e-01],\n",
       "       [9.93654013e-01, 4.95558279e-03, 1.39036251e-03],\n",
       "       [6.52658800e-03, 4.24177319e-01, 5.69296062e-01],\n",
       "       [3.32663730e-02, 7.26754487e-01, 2.39979133e-01],\n",
       "       [3.15040350e-02, 8.88030589e-01, 8.04653689e-02],\n",
       "       [7.92471910e-05, 4.82194424e-02, 9.51701283e-01],\n",
       "       [9.74787533e-01, 1.92173161e-02, 5.99516230e-03],\n",
       "       [3.47164168e-05, 2.76442301e-02, 9.72321093e-01],\n",
       "       [9.86203909e-01, 1.05282441e-02, 3.26780556e-03],\n",
       "       [9.94640708e-01, 4.09738347e-03, 1.26176747e-03],\n",
       "       [2.40627211e-02, 9.06956553e-01, 6.89806417e-02],\n",
       "       [8.81983608e-04, 1.77819312e-01, 8.21298718e-01],\n",
       "       [1.59159736e-05, 6.27665501e-03, 9.93707478e-01],\n",
       "       [4.02452610e-03, 5.37047386e-01, 4.58928019e-01],\n",
       "       [1.56442125e-04, 1.27113312e-01, 8.72730255e-01],\n",
       "       [5.28694987e-02, 8.64315867e-01, 8.28147084e-02],\n",
       "       [1.18396758e-06, 1.15158306e-02, 9.88483012e-01],\n",
       "       [2.13701222e-02, 5.54566324e-01, 4.24063504e-01],\n",
       "       [4.27973680e-02, 8.75512004e-01, 8.16905946e-02],\n",
       "       [1.42623577e-03, 2.55295783e-01, 7.43278027e-01],\n",
       "       [4.64353850e-03, 5.59205055e-01, 4.36151385e-01],\n",
       "       [8.22204575e-02, 3.85068297e-01, 5.32711267e-01],\n",
       "       [5.69513242e-04, 1.53449491e-01, 8.45981002e-01],\n",
       "       [2.72926525e-03, 7.80042827e-01, 2.17227831e-01],\n",
       "       [4.12831752e-04, 9.65647250e-02, 9.03022468e-01],\n",
       "       [1.05865777e-01, 5.48488081e-01, 3.45646143e-01],\n",
       "       [9.54032540e-01, 3.49941142e-02, 1.09733297e-02],\n",
       "       [3.05599323e-03, 1.43059447e-01, 8.53884578e-01],\n",
       "       [5.37854172e-02, 8.32078218e-01, 1.14136428e-01],\n",
       "       [1.29865795e-01, 7.54224122e-01, 1.15910158e-01],\n",
       "       [5.23820035e-02, 8.31554592e-01, 1.16063491e-01],\n",
       "       [1.72440782e-02, 7.62663484e-01, 2.20092446e-01],\n",
       "       [1.18431271e-04, 1.31747335e-01, 8.68134201e-01],\n",
       "       [9.94738996e-01, 4.02248884e-03, 1.23851339e-03],\n",
       "       [9.60649788e-01, 2.99661160e-02, 9.38405283e-03],\n",
       "       [4.82540141e-04, 1.27299011e-01, 8.72218430e-01],\n",
       "       [1.08978927e-01, 7.78713822e-01, 1.12307332e-01],\n",
       "       [9.81220961e-01, 1.43220769e-02, 4.45689540e-03],\n",
       "       [9.98576522e-01, 1.17676321e-03, 2.46741925e-04],\n",
       "       [1.55017886e-03, 6.36031747e-01, 3.62418115e-01],\n",
       "       [9.58810568e-01, 3.13638300e-02, 9.82562359e-03],\n",
       "       [6.46047946e-03, 2.28870347e-01, 7.64669180e-01],\n",
       "       [8.51458758e-02, 8.00450325e-01, 1.14403836e-01],\n",
       "       [9.86415446e-01, 1.03671970e-02, 3.21740191e-03],\n",
       "       [2.82490347e-03, 6.52412951e-01, 3.44762176e-01],\n",
       "       [5.64065249e-06, 4.89431620e-03, 9.95100081e-01],\n",
       "       [5.87066337e-02, 8.18116784e-01, 1.23176508e-01],\n",
       "       [9.46315587e-01, 4.08557318e-02, 1.28287105e-02],\n",
       "       [2.35668413e-05, 3.45464088e-02, 9.65430021e-01],\n",
       "       [2.35594180e-05, 1.64447185e-02, 9.83531713e-01],\n",
       "       [7.88659599e-05, 2.23697107e-02, 9.77551401e-01],\n",
       "       [1.51557280e-04, 4.06619124e-02, 9.59186554e-01],\n",
       "       [9.96213496e-01, 2.89694360e-03, 8.89526913e-04],\n",
       "       [9.84405816e-01, 1.18976189e-02, 3.69663863e-03],\n",
       "       [6.52859861e-04, 1.10082716e-01, 8.89264405e-01],\n",
       "       [1.52065433e-04, 4.32585441e-02, 9.56589401e-01],\n",
       "       [2.06571668e-01, 7.01523423e-01, 9.19049829e-02],\n",
       "       [4.22994082e-04, 2.16054078e-02, 9.77971613e-01],\n",
       "       [9.38550353e-01, 4.72092107e-02, 1.42405173e-02],\n",
       "       [1.82133156e-03, 9.54230353e-02, 9.02755558e-01],\n",
       "       [7.92992359e-05, 5.44266738e-02, 9.45493996e-01],\n",
       "       [9.76122022e-01, 1.82021763e-02, 5.67585416e-03],\n",
       "       [9.93338346e-01, 5.09106461e-03, 1.57060754e-03],\n",
       "       [2.45184667e-04, 3.16656649e-01, 6.83098137e-01],\n",
       "       [9.89677072e-01, 7.88228493e-03, 2.44060741e-03],\n",
       "       [9.51155901e-01, 3.71793360e-02, 1.16647072e-02],\n",
       "       [9.96220767e-01, 2.92135286e-03, 8.57856183e-04],\n",
       "       [3.01812645e-02, 8.47525656e-01, 1.22293092e-01],\n",
       "       [2.56693093e-05, 1.35862213e-02, 9.86388028e-01],\n",
       "       [2.99837734e-06, 1.90606397e-02, 9.80936408e-01],\n",
       "       [9.90198135e-01, 7.48519646e-03, 2.31665280e-03],\n",
       "       [9.58674967e-01, 3.14668976e-02, 9.85819008e-03],\n",
       "       [9.85599160e-01, 1.09888259e-02, 3.41199129e-03],\n",
       "       [4.49899584e-02, 8.09788764e-01, 1.45221323e-01],\n",
       "       [4.41001495e-03, 8.09252262e-01, 1.86337635e-01],\n",
       "       [9.75318491e-01, 1.88133642e-02, 5.86808380e-03],\n",
       "       [9.70230818e-01, 2.26828903e-02, 7.08631333e-03],\n",
       "       [7.86286127e-03, 8.74520302e-01, 1.17616877e-01],\n",
       "       [9.82129633e-01, 1.36304554e-02, 4.23989538e-03],\n",
       "       [2.56936374e-07, 4.95304214e-03, 9.95046735e-01],\n",
       "       [9.78723690e-02, 8.03675234e-01, 9.84523594e-02],\n",
       "       [2.80157838e-05, 4.65995781e-02, 9.53372359e-01],\n",
       "       [5.35347499e-03, 8.14063907e-01, 1.80582657e-01],\n",
       "       [9.98883188e-01, 8.56459665e-04, 2.60333152e-04],\n",
       "       [6.09411113e-03, 2.83321291e-01, 7.10584641e-01],\n",
       "       [9.97827590e-01, 1.71051861e-03, 4.61850141e-04],\n",
       "       [2.48816650e-06, 2.69312859e-02, 9.73066211e-01],\n",
       "       [9.96307731e-01, 2.82509066e-03, 8.67282390e-04],\n",
       "       [9.68389392e-01, 2.40830630e-02, 7.52759632e-03],\n",
       "       [1.74785837e-05, 7.16624111e-02, 9.28320110e-01],\n",
       "       [9.80010211e-01, 1.52436178e-02, 4.74617025e-03],\n",
       "       [1.19437471e-04, 1.11564612e-02, 9.88724053e-01],\n",
       "       [5.01309410e-02, 8.39493632e-01, 1.10375352e-01],\n",
       "       [3.90606187e-02, 8.75022769e-01, 8.59165266e-02],\n",
       "       [6.15364052e-02, 8.54921639e-01, 8.35419819e-02],\n",
       "       [1.39369644e-04, 2.27656588e-02, 9.77094889e-01],\n",
       "       [4.56987327e-05, 2.42229272e-02, 9.75731432e-01],\n",
       "       [3.02915392e-03, 5.85863769e-01, 4.11107004e-01],\n",
       "       [1.13114074e-03, 3.63741547e-01, 6.35127306e-01],\n",
       "       [9.20454085e-01, 6.19020797e-02, 1.76438242e-02],\n",
       "       [4.56536226e-02, 8.79685760e-01, 7.46605620e-02],\n",
       "       [2.12998639e-05, 1.06337965e-02, 9.89344895e-01],\n",
       "       [3.05599323e-03, 1.43059447e-01, 8.53884578e-01],\n",
       "       [9.84737456e-01, 1.16451010e-02, 3.61752650e-03],\n",
       "       [4.22667060e-03, 8.48109603e-01, 1.47663683e-01],\n",
       "       [1.33533716e-01, 7.42013574e-01, 1.24452710e-01],\n",
       "       [1.57021713e-02, 2.90320218e-01, 6.93977654e-01],\n",
       "       [3.83556401e-03, 8.48643780e-01, 1.47520632e-01],\n",
       "       [9.90229547e-01, 7.46120140e-03, 2.30916496e-03],\n",
       "       [9.94373798e-01, 4.30111773e-03, 1.32504152e-03],\n",
       "       [9.58674967e-01, 3.14668976e-02, 9.85819008e-03],\n",
       "       [1.18329679e-03, 1.58805147e-01, 8.40011537e-01],\n",
       "       [4.77305092e-02, 8.72474551e-01, 7.97949284e-02],\n",
       "       [8.85496593e-06, 1.33884531e-02, 9.86602664e-01],\n",
       "       [9.73296165e-01, 2.03516483e-02, 6.35213777e-03]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = ann.predict(X_train)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "emerging-crime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 2, 1, 0, 2, 1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 1, 2, 1, 2,\n",
       "       1, 1, 2, 1, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0,\n",
       "       1, 0, 2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 0, 2, 2,\n",
       "       0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1,\n",
       "       0, 2, 0, 2, 0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 2, 0, 1, 2, 2, 0, 1,\n",
       "       1, 2, 1, 0, 0, 0, 2, 1, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ypred>0.5\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "spoken-agency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2,\n",
       "       1, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0,\n",
       "       1, 0, 2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2,\n",
       "       0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1,\n",
       "       0, 2, 0, 2, 0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 2, 1, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_ = y_train>0.5\n",
    "ytrain_ = np.argmax(ytrain_,axis=1)\n",
    "ytrain_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-double",
   "metadata": {},
   "source": [
    "# Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "completed-ocean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38  1  0]\n",
      " [ 0 34  3]\n",
      " [ 0  2 42]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(ytrain_, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(ytrain_, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-recall",
   "metadata": {},
   "source": [
    "# Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "illegal-symphony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.41552203e-04, 1.44772334e-02, 9.85281169e-01],\n",
       "       [1.12524685e-02, 9.37956154e-01, 5.07913828e-02],\n",
       "       [9.98835027e-01, 9.19520680e-04, 2.45500356e-04],\n",
       "       [3.95812895e-05, 9.65223461e-02, 9.03438091e-01],\n",
       "       [9.85014260e-01, 1.14343325e-02, 3.55150667e-03],\n",
       "       [3.62225364e-05, 4.60786093e-03, 9.95355964e-01],\n",
       "       [9.90614653e-01, 7.16775004e-03, 2.21759873e-03],\n",
       "       [3.02542327e-03, 6.73329473e-01, 3.23645055e-01],\n",
       "       [1.61791255e-03, 7.41364419e-01, 2.57017612e-01],\n",
       "       [1.66274197e-02, 8.83676946e-01, 9.96955931e-02],\n",
       "       [6.19106041e-03, 5.48044264e-01, 4.45764661e-01],\n",
       "       [1.58644468e-02, 7.04906881e-01, 2.79228687e-01],\n",
       "       [1.60165373e-02, 8.66769314e-01, 1.17214225e-01],\n",
       "       [3.22635798e-03, 6.72443628e-01, 3.24330002e-01],\n",
       "       [1.42440759e-02, 7.43818343e-01, 2.41937622e-01],\n",
       "       [9.58674967e-01, 3.14668976e-02, 9.85819008e-03],\n",
       "       [1.61572024e-02, 6.80694699e-01, 3.03148121e-01],\n",
       "       [6.48766086e-02, 8.42740357e-01, 9.23829451e-02],\n",
       "       [9.40744460e-01, 4.50861938e-02, 1.41693410e-02],\n",
       "       [9.97565746e-01, 1.86403224e-03, 5.70269825e-04],\n",
       "       [4.57196124e-03, 1.10349469e-01, 8.85078549e-01],\n",
       "       [5.81011660e-02, 6.50656283e-01, 2.91242629e-01],\n",
       "       [9.80399370e-01, 1.49474721e-02, 4.65319166e-03],\n",
       "       [9.25578237e-01, 5.65984845e-02, 1.78232882e-02],\n",
       "       [2.43170396e-03, 2.76808739e-01, 7.20759571e-01],\n",
       "       [9.95455861e-01, 3.47544136e-03, 1.06877659e-03],\n",
       "       [9.94702160e-01, 4.05055797e-03, 1.24722789e-03],\n",
       "       [1.39910281e-02, 8.64167690e-01, 1.21841244e-01],\n",
       "       [6.23045452e-02, 8.49533141e-01, 8.81623030e-02],\n",
       "       [9.82072532e-01, 1.36739342e-02, 4.25353367e-03]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = ann.predict(X_test)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "offshore-upset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = ypred>0.5\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "voluntary-leeds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest_ = y_test>0.5\n",
    "ytest_ = np.argmax(ytest_,axis=1)\n",
    "ytest_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-heath",
   "metadata": {},
   "source": [
    "# Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "annual-michael",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1  5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(ytest_, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(ytest_, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "backed-reliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives\n",
      " [0 1 0]\n",
      "False Negetives\n",
      " [0 0 1]\n",
      "True Positives\n",
      " [11 13  5]\n",
      "True Negetives\n",
      " [19 16 24]\n",
      "Sensitivity \n",
      " [1.         1.         0.83333333]\n",
      "Specificity \n",
      " [1.         0.94117647 1.        ]\n",
      "Precision \n",
      " [1.         0.92857143 1.        ]\n",
      "Recall \n",
      " [1.         1.         0.83333333]\n",
      "Áccuracy \n",
      "[1.         0.96666667 0.96666667]\n",
      "FScore \n",
      "[1.         0.96296296 0.90909091]\n"
     ]
    }
   ],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)\n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "print('False Positives\\n {}'.format(FP))\n",
    "print('False Negetives\\n {}'.format(FN))\n",
    "print('True Positives\\n {}'.format(TP))\n",
    "print('True Negetives\\n {}'.format(TN))\n",
    "TPR = TP/(TP+FN)\n",
    "print('Sensitivity \\n {}'.format(TPR))\n",
    "TNR = TN/(TN+FP)\n",
    "print('Specificity \\n {}'.format(TNR))\n",
    "Precision = TP/(TP+FP)\n",
    "print('Precision \\n {}'.format(Precision))\n",
    "Recall = TP/(TP+FN)\n",
    "print('Recall \\n {}'.format(Recall))\n",
    "Acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "print('Áccuracy \\n{}'.format(Acc))\n",
    "Fscore = 2*(Precision*Recall)/(Precision+Recall)\n",
    "print('FScore \\n{}'.format(Fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "serious-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model.history['loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-horizon",
   "metadata": {},
   "source": [
    "# plot of the loss vs. epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "exact-absence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epoch_count, training_loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-london",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
